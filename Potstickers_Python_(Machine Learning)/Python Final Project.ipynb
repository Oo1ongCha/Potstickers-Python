{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f79b6d97-4b98-46cf-b4e0-9b3f77482b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install statsmodels\n",
    "# %pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157bebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels import stats\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mean_absolute_error(y, yp):\n",
    "    mae = sum(abs(y - yp)) / len(y)\n",
    "    return mae\n",
    "\n",
    "df = pd.read_csv('MLclass_PISAData.csv', encoding='gbk', index_col=['CNTSTUID'])\n",
    "data = df.copy()\n",
    "#print (data.describe())\n",
    "data.pop('CNTRYID')\n",
    "data.pop('CNT')\n",
    "data.pop('CNTSCHID')\n",
    "data.pop('SN')\n",
    "#print(data.columns)\n",
    "for col in data.columns:\n",
    "    if data[col].dtypes== 'object':\n",
    "        data[col]=pd.to_numeric(data[col],errors='coerce')\n",
    "\n",
    "data[np.isnan(data)] = 0\n",
    "\n",
    "#print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344dc5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 PVSCIE   R-squared:                       0.990\n",
      "Model:                            OLS   Adj. R-squared:                  0.990\n",
      "Method:                 Least Squares   F-statistic:                 2.751e+04\n",
      "Date:                Sun, 12 May 2024   Prob (F-statistic):               0.00\n",
      "Time:                        23:07:05   Log-Likelihood:                -28345.\n",
      "No. Observations:                7708   AIC:                         5.675e+04\n",
      "Df Residuals:                    7679   BIC:                         5.695e+04\n",
      "Df Model:                          28                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.7123      0.855      0.833      0.405      -0.965       2.389\n",
      "PVMATH         0.0613      0.003     17.690      0.000       0.055       0.068\n",
      "PVREAD         0.0701      0.004     17.936      0.000       0.062       0.078\n",
      "PVSCEP         0.1466      0.009     16.884      0.000       0.130       0.164\n",
      "PVSCED         0.0773      0.006     13.411      0.000       0.066       0.089\n",
      "PVSCID         0.0769      0.007     11.078      0.000       0.063       0.090\n",
      "PVSKCO         0.1257      0.008     14.992      0.000       0.109       0.142\n",
      "PVSKPE         0.1530      0.009     17.080      0.000       0.135       0.171\n",
      "PVSSPH         0.0902      0.006     15.711      0.000       0.079       0.101\n",
      "PVSSLI         0.1232      0.007     17.670      0.000       0.110       0.137\n",
      "PVSSES         0.0747      0.006     12.252      0.000       0.063       0.087\n",
      "SMINS       1.509e-08   1.04e-08      1.449      0.148   -5.33e-09    3.55e-08\n",
      "SMINH          0.1431      0.061      2.331      0.020       0.023       0.263\n",
      "ESCS          -0.2803      0.155     -1.811      0.070      -0.584       0.023\n",
      "IBTEACH       -0.1335      0.114     -1.172      0.241      -0.357       0.090\n",
      "TEACHSUP      -0.2610      0.142     -1.841      0.066      -0.539       0.017\n",
      "ENVAWARE       0.3220      0.123      2.614      0.009       0.081       0.563\n",
      "JOYSCIE        0.6541      0.147      4.442      0.000       0.365       0.943\n",
      "INTBRSCI       0.1620      0.169      0.957      0.338      -0.170       0.494\n",
      "SCIEEFF        0.0186      0.112      0.167      0.868      -0.200       0.237\n",
      "MOTIVAT       -0.5312      0.138     -3.854      0.000      -0.801      -0.261\n",
      "EPIST          0.4563      0.126      3.619      0.000       0.209       0.703\n",
      "ICTHOME        0.1418      0.047      3.016      0.003       0.050       0.234\n",
      "INTICT        -0.3534      0.145     -2.430      0.015      -0.638      -0.068\n",
      "COMPICT       -0.2259      0.175     -1.288      0.198      -0.570       0.118\n",
      "AUTICT         0.4397      0.163      2.702      0.007       0.121       0.759\n",
      "INSTSCIE       0.0209      0.019      1.130      0.259      -0.015       0.057\n",
      "TDTEACH        0.0111      0.019      0.593      0.553      -0.026       0.048\n",
      "ADINST        -0.0137      0.018     -0.744      0.457      -0.050       0.022\n",
      "==============================================================================\n",
      "Omnibus:                        6.146   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.046   Jarque-Bera (JB):                6.287\n",
      "Skew:                           0.049   Prob(JB):                       0.0431\n",
      "Kurtosis:                       3.100   Cond. No.                     8.50e+07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.5e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = data.pop('PVSCIE')\n",
    "\n",
    "# https://reurl.cc/mMoMWM\n",
    "# Statistic\n",
    "data = sm.add_constant(data)\n",
    "Statistic = sm.OLS(target,data).fit()\n",
    "print(Statistic.summary())\n",
    "print()\n",
    "\n",
    "# Residual\n",
    "res = target - Statistic.fittedvalues\n",
    "#print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fac0ca7-11db-4bb8-aa3e-8341639cfdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P value = 0.04628030069180523\n",
      "The Residual is not normally distributed.\n",
      "\n",
      "Durbin-Watson Test : 2.0061659621546384\n",
      "t-statistic = 2.0061659621546384\n",
      "P-Value = 0.022436710855715743\n",
      "The Residual is not independent.\n",
      "\n",
      "P-Value of Variance Hemogeneity = 0.0001506730997862439\n",
      "The Variance of Residual is not Homogeneity.\n",
      "\n",
      "Mean MAE =  8.327\n",
      "Std 0f MAE =  0.606\n",
      "\n",
      "Mean Score of Train Set =  0.99\n",
      "Std Score of Train Set =  0.002\n",
      "\n",
      "Mean Score of Test Set =  0.986\n",
      "Std Score of Test Set =  0.006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_performance_test = 0\n",
    "order = 0\n",
    "\n",
    "#建立線性回歸時，必須要檢驗殘差(Residaul)是否符合以下三個假設：\n",
    "#\t• 常態性 ( Normality )\n",
    "#\t• 獨立性 ( Independence )\n",
    "#\t• 變異數同質性 ( Homogeneity of Variance )\n",
    "\n",
    "# Normalty \n",
    "# Not Normal distribution, if p-value < 0.05  \n",
    "#print (scipy.stats.shapiro(res))\n",
    "#if (scipy.stats.shapiro(res).pvalue < 0.05) : print ('The Residual is not normally distributed')\n",
    "#else : print ('The Residual is normally distributed')\n",
    "#print()\n",
    "\n",
    "res_pvalue = scipy.stats.mstats.normaltest(res)\n",
    "print('P value =', res_pvalue.pvalue)\n",
    "if (res_pvalue.pvalue < 0.05) : print ('The Residual is not normally distributed.')\n",
    "else : print ('The Residual is normally distributed.')\n",
    "print()\n",
    "\n",
    "# Sample Inependence\n",
    "# 每個殘差之間互為獨立：可使用 Durban-Watson test 檢定每個殘差之間是否獨立。\n",
    "# p-value > 0.05：接受虛無假設，代表每個殘差之間互為獨立。\n",
    "tstatistic = stats.stattools.durbin_watson(res) # 計算出 T 統計量\n",
    "print('Durbin-Watson Test :', tstatistic )\n",
    "tpvalue = scipy.stats.t.sf(tstatistic, len(res)-1) # 將統計量轉換成 p-value\n",
    "print('t-statistic =', tstatistic)\n",
    "print('P-Value =', tpvalue)\n",
    "if (tpvalue < 0.05) : print ('The Residual is not independent.')\n",
    "else : print ('The Residual is independent.')\n",
    "print()\n",
    "\n",
    "# Variance Homogeneity\n",
    "# 殘差變異數一致性：使用 Breusch-Pagan Test 檢測殘差變異數是否一致\n",
    "#  p-value < 0.05：拒絕虛無假設，代表殘差變異數不一致。\n",
    "print('P-Value of Variance Hemogeneity =', sms.het_breuschpagan(res, Statistic.model.exog)[3])\n",
    "if (sms.het_breuschpagan(res, Statistic.model.exog)[3] < 0.05) : print ('The Variance of Residual is not Homogeneity.')\n",
    "else : print ('The Variance of Residual is Homogeneity.')\n",
    "print()\n",
    "    \n",
    "\n",
    "mean_performance_train = []\n",
    "mean_performance_test = []\n",
    "mean_MAE = []\n",
    "\n",
    "run_times = 100\n",
    "\n",
    "for i in range (run_times):\n",
    "    # start training and testing the multiple regression model\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data.values, target.values, test_size=0.2)\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    \n",
    "    #reg_model = LinearRegression()\n",
    "    \n",
    "    #reg_model.fit(data_train, target_train)\n",
    "    poly_model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "    poly_model.fit(data_train, target_train)\n",
    "    \n",
    "    #predictions = reg_model.predict(data_test)\n",
    "    predictions = poly_model.predict(data_test)\n",
    "\n",
    "    mean_MAE.append(mean_absolute_error(target_test,predictions))\n",
    "    mean_performance_train.append(poly_model.score(data_train, target_train))\n",
    "    mean_performance_test.append(poly_model.score(data_test, target_test))\n",
    "\n",
    "print( 'Mean MAE = ', np.mean(mean_MAE).round(3))\n",
    "print( 'Std 0f MAE = ', np.std(mean_MAE).round(3))\n",
    "print()\n",
    "print( 'Mean Score of Train Set = ', np.mean(mean_performance_train).round(3))\n",
    "print( 'Std Score of Train Set = ', np.std(mean_performance_train).round(3))\n",
    "print()\n",
    "print( 'Mean Score of Test Set = ', np.mean(mean_performance_test).round(3))\n",
    "print( 'Std Score of Test Set = ', np.std(mean_performance_test).round(3))\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
